{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " 8. 뉴스 기사의 댓글 정보  수집하기\n",
      "================================================================================\n",
      "\n",
      "\n",
      "1.댓글을 크롤링할 뉴스의 URL을 입력하세요: https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=056&aid=0010661268\n",
      "2.크롤링 할 건수는 몇건입니까?(10건단위로 입력요망): 30\n",
      "3.파일을 저장할 폴더명만 쓰세요(예:c:\\temp\\):c:\\data\\\n",
      "================================================================================\n",
      "전체 검색 결과 건수 : 504 건\n",
      "실제 최종 출력 건수 30\n",
      "실체 출력될 최종 페이지수 2\n",
      "\n",
      "\n",
      "1 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: ehdd****\n",
      "2.리뷰: 어떻게든 한국미세먼지 탓도있다고 보도하려고 애쓰네ㅋㅋ\n",
      "3.작성일자: 2019.01.15. 16:10:23\n",
      "4.공감: 2016\n",
      "5.비공감: 56\n",
      "\n",
      "\n",
      "2 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: siho****\n",
      "2.리뷰: 진짜 쓰레기 보다 못한 기사다 그래서 어쩌 자는거냐? 누가 심한거 모르냐? 정상 적인 언론이라면 지금에 미세먼지 원인이 뭐고 앞으로 나가야할 정부 정책에는 뭐가 있고 뭔가 대책과 무능한 정부에 질책이나 문제점을 쓰는게 맞을듯 싶은데 누가 미세먼지 나쁘다는것에 부정하는 사람있냐? 국민세금이 아깝다\n",
      "3.작성일자: 2019.01.15. 16:26:58\n",
      "4.공감: 725\n",
      "5.비공감: 37\n",
      "\n",
      "\n",
      "3 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: reds****\n",
      "2.리뷰: 충남공장 사진은 왜 올리는거지\n",
      "3.작성일자: 2019.01.15. 16:38:26\n",
      "4.공감: 519\n",
      "5.비공감: 4\n",
      "\n",
      "\n",
      "4 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: daup****\n",
      "2.리뷰: 더럽고 역겨운 종북좌빨 적폐 더불어강간당의 충실한 애완견으로 전락한 방송국 기레기 삽팔놈들아! 개소리 작작하고 중국산 미세면지라고 당당하게 진실을 보도해라!\n",
      "3.작성일자: 2019.01.15. 16:44:21\n",
      "4.공감: 451\n",
      "5.비공감: 89\n",
      "\n",
      "\n",
      "5 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: samk****\n",
      "2.리뷰: 애쓴다ㅋㅋㅋㅋㅋㅋ\n",
      "3.작성일자: 2019.01.15. 16:55:12\n",
      "4.공감: 137\n",
      "5.비공감: 7\n",
      "\n",
      "\n",
      "6 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: mark****\n",
      "2.리뷰: 기자님. 잘 모르는건 대충 짐작으로 글 적지 마세요. 중간 충남 공장 사진에 오염물질을 뿜어대는 공장이라고 글을 다셨는데, 저거 거의 다 수증기입니다. TEMS 때문에 실시간 감시되서 오염물질 뿜어대질 못해요. 제대로 조사 안한 내용이나 모르는건 상상력으로 기사 적지 마세요. 그러니 잘 못된 기사가 나오고 뇌피셜 소리나 듣는겁니다.\n",
      "3.작성일자: 2019.01.15. 17:27:44\n",
      "4.공감: 71\n",
      "5.비공감: 3\n",
      "\n",
      "\n",
      "7 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: dusc****\n",
      "2.리뷰: 중국탓인줄 국민들은 다 압니다  바보로 알지 마세요\n",
      "3.작성일자: 2019.01.15. 17:28:15\n",
      "4.공감: 61\n",
      "5.비공감: 2\n",
      "\n",
      "\n",
      "8 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: hubb****\n",
      "2.리뷰: 이정훈기자 몇년전부터 꾸준히 미세먼지 국내발요인으로 물타기하는 걸레짝만도 못한 쓰레기 기자입니다. 국내 평상시 초미세먼지 수치가 20대라면 그중 국내요인이 절반이라해도 10인데 요며칠 초미세수치가 150이된건 중국에서 몰려온 스모그로밖엔 설명이 안됩니다. 대기정체 지껄이는데 그럼 울릉도 제주도 백령도는 어떻게 설명할래?\n",
      "3.작성일자: 2019.01.15. 17:30:01\n",
      "4.공감: 56\n",
      "5.비공감: 2\n",
      "\n",
      "\n",
      "9 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: seun****\n",
      "2.리뷰 : 작성자에 의해 삭제된 댓글입니다\n",
      "3.작성일자: 2019.04.08. 11:04:22\n",
      "4.공감 : 0\n",
      "5.비공감 : 0\n",
      "\n",
      "\n",
      "10 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: kim7****\n",
      "2.리뷰: 문정부를 응원하는 지지자로써 미세먼지 대책은 한없이 부족하다고 느낍니다초딩들도 미세먼지 중국에서 온다는거 아는데 쓸데없이 차량2부제드립이나 차공회전 금지같은 엉터리 정책이나 내놓고...요새 차기술력이 얼마나 발달했는데 차 배기가스 그거 줄인다고 미세먼지가 얼마나 줄어들까요?중국한테 찍소리못하고 개탄스러움\n",
      "3.작성일자: 2019.01.15. 17:28:13\n",
      "4.공감: 30\n",
      "5.비공감: 2\n",
      "\n",
      "\n",
      "11 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: rua0****\n",
      "2.리뷰: 이정훈기자, 제가 몇번이나 말했는데..참...당신이 마지막에 써 놓은 중국발+국내발+기상조건 이라고 하는데.이 3가지를 하나하나 퍼센트로 나누면 어떻게 될까요?중국발이 몇퍼센트 차지하고 국내발 몇퍼센트 차지할거라고 보세요?기상전문가에 미세먼지에 관심이 높으신 ‘한국인’기자님.당신이 미세먼지에 관심이 많아서 몇년전부터 기사 쓴거 압니다.당신이 말하고자 하는 합리적인 생각을 모르는게 아니에요.국내발도 있다고 하는데, 있긴하겠죠. 근데 그거 줄여도 우리는 깨끗한공기 못마십니다.기사에 쓰여있듯이, 윗공기 빨대도 빨아마셔야지요\n",
      "3.작성일자: 2019.01.15. 17:25:50\n",
      "4.공감: 28\n",
      "5.비공감: 1\n",
      "\n",
      "\n",
      "12 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: jihy****\n",
      "2.리뷰: 충남지역 공장말고 중국공장 사진도 올려주세요^^ 되도않는 헛소리 작작하시구요ㅎㅎ\n",
      "3.작성일자: 2019.01.15. 17:22:40\n",
      "4.공감: 24\n",
      "5.비공감: 0\n",
      "\n",
      "\n",
      "13 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: summ****\n",
      "2.리뷰: 대선 공약으로 자기 뽑아주면 중국과 나라답게 당당하게 얘기해서 미세먼지 최우선 해결한다고 떵떵거리며 얘기하더니 지금 이게 뭔가여? 다른 것도 모두 마찬가지죠. 공약 지킨거 하나도 없고 다 감성팔이 말뿐이고 오로지 북한만 퍼주고 이게 나라인가요? 소득 주도 고집해서 물가폭등 실업자폭증 주가폭락 부동산폭등 금리폭등 자영업자 몰락 너무나 힘든 서민들 많습니다. 이런데도 잘못 인정 안하고 작년말이면 좋아진다 올해면 좋아진다 계속 거짓말 하고 마지막에 뒷통수 치고 이게 나라인가요?\n",
      "3.작성일자: 2019.01.15. 17:29:28\n",
      "4.공감: 14\n",
      "5.비공감: 0\n",
      "\n",
      "\n",
      "14 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: slsl****\n",
      "2.리뷰: 중국이라는 말을 왜 못하는거냐? 세금 걷어가서 뭐하길래 환경부담금이다 자동차세다 뭐다 다 걷어가서는 왜 ㅈㄹ인데 애초에 걷어가지 말고 그러던가 그리고 어떻게든 국내 문제로 돌리려고 애쓰는것 같은데 기자야 장난하냐?! 국민들은 멍청이가 아니다\n",
      "3.작성일자: 2019.01.15. 17:28:27\n",
      "4.공감: 11\n",
      "5.비공감: 0\n",
      "\n",
      "\n",
      "15 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: jhak****\n",
      "2.리뷰 : 작성자에 의해 삭제된 댓글입니다\n",
      "3.작성일자: 2019.01.15. 21:17:53\n",
      "4.공감 : 0\n",
      "5.비공감 : 0\n",
      "\n",
      "\n",
      "16 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: blas****\n",
      "2.리뷰: 유독 KBS만 중국을 싸고 도네!\n",
      "3.작성일자: 2019.01.15. 18:33:19\n",
      "4.공감: 8\n",
      "5.비공감: 0\n",
      "\n",
      "\n",
      "17 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: ziwh****\n",
      "2.리뷰: KBS쓰레기방송\n",
      "3.작성일자: 2019.01.15. 17:32:57\n",
      "4.공감: 8\n",
      "5.비공감: 0\n",
      "\n",
      "\n",
      "18 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: gago****\n",
      "2.리뷰: 단순히 현재 상황 알려주려고 악조건속에서도 위험하게 헬기 촬영이 무슨 의미가 있는거냐!? 분석도 해결 방법 제시도 없는...\n",
      "3.작성일자: 2019.01.15. 17:12:22\n",
      "4.공감: 8\n",
      "5.비공감: 2\n",
      "\n",
      "\n",
      "19 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: hyun****\n",
      "2.리뷰: 진짜 어이없네 우리나라 80년대 버스 에서 시커먼 매연 내뿜고 공장 많을때도 하늘은 맑았다이걸 자꾸 국내요인 걸고 넘어지는데 말이 된다고 생각하나 진짜?\n",
      "3.작성일자: 2019.01.15. 18:03:00\n",
      "4.공감: 6\n",
      "5.비공감: 0\n",
      "\n",
      "\n",
      "20 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: dlcn****\n",
      "2.리뷰: 역시 국내문제로 몰아가는군.힘없는나라~밥줄생각안하는 노후경후차 단속하고 잘지켜지지도않는 2부제시행하고 패턴은 반복될거고일본의 미세먼지 상황을봐라~왜 헬조선인지 알거다. 마스크 쓰고 놀고있던 아이들한테 미안한마음이 들더라\n",
      "3.작성일자: 2019.01.15. 17:32:21\n",
      "4.공감: 6\n",
      "5.비공감: 0\n",
      "\n",
      "\n",
      "21 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: bern****\n",
      "2.리뷰: 대통령님 그냥 솔직히 발표해요. 중국이 너무 강한 나라라서 잘못 건들면 우리 경제 파탄난다. 그리고 중국과 틀어지면 북한과도 다시 멀어진다. 국민 여러분 많이 힘드시죠? 저희가 어떻게든 해결책을 찾고 있으니 좀 더 힘내주십시오, 라고. 이 쉬운 말을 왜 못 합니까.. 지지율 떨어지는 거 무서우신 거죠? 손바닥으로 하늘을 가리세요. 떨어지면 더 잘해서 다시 올리는 게 대통령이예요\n",
      "3.작성일자: 2019.01.16. 09:58:56\n",
      "4.공감: 5\n",
      "5.비공감: 0\n",
      "\n",
      "\n",
      "22 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: sush****\n",
      "2.리뷰: Kbs  이와중에 충남아산공장사진 보여주네. ㅋㅋ 이런미세먼지는 중국이야\n",
      "3.작성일자: 2019.01.15. 21:36:16\n",
      "4.공감: 5\n",
      "5.비공감: 0\n",
      "\n",
      "\n",
      "23 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: grea****\n",
      "2.리뷰: 중국 96% 한국 4%임. 한국에 차량만 2000만대, 공장도 수백만개가 있는데 한국이 뿜어내는 오염물질이 없을 수가 없지.\n",
      "3.작성일자: 2019.01.15. 20:25:50\n",
      "4.공감: 5\n",
      "5.비공감: 0\n",
      "\n",
      "\n",
      "24 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: cup9****\n",
      "2.리뷰 : 작성자에 의해 삭제된 댓글입니다\n",
      "3.작성일자: 2019.01.15. 22:27:11\n",
      "4.공감 : 0\n",
      "5.비공감 : 0\n",
      "\n",
      "\n",
      "25 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: yein****\n",
      "2.리뷰: 이정훈 기자님 돈 받으신건가요? 기자로 직업이면 이정도 분별은 할텐데..가릴걸 가리고 우길걸 우깁시다 예?\n",
      "3.작성일자: 2019.01.15. 17:27:35\n",
      "4.공감: 5\n",
      "5.비공감: 0\n",
      "\n",
      "\n",
      "26 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: wass****\n",
      "2.리뷰: 충남지역공장은 뭐냐??미세먼지 없는날도 저기 가동되는지 안되는지 올려라\n",
      "3.작성일자: 2019.01.15. 17:24:17\n",
      "4.공감: 5\n",
      "5.비공감: 0\n",
      "\n",
      "\n",
      "27 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: mung****\n",
      "2.리뷰 : 작성자에 의해 삭제된 댓글입니다\n",
      "3.작성일자: 2019.04.30. 04:23:17\n",
      "4.공감 : 0\n",
      "5.비공감 : 0\n",
      "\n",
      "\n",
      "28 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: yo_9****\n",
      "2.리뷰: 그 옛날 영국도.스모그 탓으로 몇백만명이 일주일만에 죽었다고 하니.. 정말 사람이 살 수 없게 되어 가고 있다. 대통령은 뭐하나? 공약도안지키고!\n",
      "3.작성일자: 2019.01.16. 13:18:18\n",
      "4.공감: 4\n",
      "5.비공감: 0\n",
      "\n",
      "\n",
      "29 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: nnni****\n",
      "2.리뷰: 국내원인은 개소리다. 한중일 초미세먼지 예측영상보면 그냥 중국에서부터 서해바다 끼고 한반도까지 뻘건 고농도 초미세먼지가 그대로 연결되서 한반도를 직통한다. 국영방송이 이렇게 대놓고 ㅉㅉㅉ\n",
      "3.작성일자: 2019.01.16. 07:01:55\n",
      "4.공감: 4\n",
      "5.비공감: 0\n",
      "\n",
      "\n",
      "30 번째 댓글 수집 중 ==================\n",
      "1.작성자ID: mem0****\n",
      "2.리뷰: 공중파들 얼마 받아쳐먹옸길래 은폐하고 왜곡하냐...???\n",
      "3.작성일자: 2019.01.15. 23:29:36\n",
      "4.공감: 4\n",
      "5.비공감: 0\n",
      "30 건  완료========================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "1.요청된 총 30 건의 리뷰 중에서 실제 크롤링 된 리뷰수는 30 건입니다\n",
      "2.총 소요시간은 24.9 초 입니다 \n",
      "3.파일 저장 완료: txt 파일명 : c:\\data\\2019-05-12-07-39-10-뉴스기사댓글\\2019-05-12-07-39-10-뉴스기사댓글.txt \n",
      "4.파일 저장 완료: csv 파일명 : c:\\data\\2019-05-12-07-39-10-뉴스기사댓글\\2019-05-12-07-39-10-뉴스기사댓글.csv \n",
      "5.파일 저장 완료: xls 파일명 : c:\\data\\2019-05-12-07-39-10-뉴스기사댓글\\2019-05-12-07-39-10-뉴스기사댓글.xls \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Chap 8. 다양한 댓글 모으기\n",
    "#  뉴스 기사의 댓글 모으기 - 미세먼지 / 스모그  \n",
    "# 테스트 기사 URL : https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=056&aid=0010661268\n",
    "\n",
    "#Step 1. 필요한 모듈과 라이브러리를 로딩합니다.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import math\n",
    "import numpy  \n",
    "import pandas as pd  \n",
    "import random\n",
    "import os\n",
    "\n",
    "#Step 2. 사용자에게 검색어 키워드를 입력 받고 저장할 폴더와 파일명을 설정합니다.\n",
    "print(\"=\" *80)\n",
    "print(\" 8. 뉴스 기사의 댓글 정보  수집하기\")\n",
    "print(\"=\" *80)\n",
    "print(\"\\n\")\n",
    "\n",
    "query_txt = '뉴스기사댓글'\n",
    "query_url = input('1.댓글을 크롤링할 뉴스의 URL을 입력하세요: ')\n",
    "cnt = int(input('2.크롤링 할 건수는 몇건입니까?(10건단위로 입력요망): '))\n",
    "page_cnt = math.ceil(cnt / 20)\n",
    "\n",
    "f_dir = input(\"3.파일을 저장할 폴더명만 쓰세요(예:c:\\\\temp\\\\):\")\n",
    "\n",
    "# 저장될 파일위치와 이름을 지정합니다\n",
    "now = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec)\n",
    "\n",
    "os.makedirs(f_dir+s+'-'+query_txt)\n",
    "os.chdir(f_dir+s+'-'+query_txt)\n",
    "\n",
    "ff_name=f_dir+s+'-'+query_txt+'\\\\'+s+'-'+query_txt+'.txt'\n",
    "fc_name=f_dir+s+'-'+query_txt+'\\\\'+s+'-'+query_txt+'.csv'\n",
    "fx_name=f_dir+s+'-'+query_txt+'\\\\'+s+'-'+query_txt+'.xls'\n",
    "\n",
    "#Step 3. 크롬 드라이버를 사용해서 웹 브라우저를 실행합니다.\n",
    "\n",
    "s_time = time.time( )\n",
    "\n",
    "path = \"c:/temp/chromedriver_240/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.get(query_url)\n",
    "time.sleep(5)\n",
    "\n",
    "#Step 4. 현재 총 리뷰 건수를 확인하여 사용자의 요청건수와 비교 후 동기화합니다\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "result= soup.find('div', class_='u_cbox_head').find('span','u_cbox_count')\n",
    "result2 = result.get_text()\n",
    "\n",
    "print(\"=\" *80)\n",
    "result3 = result2.replace(\",\",\"\")\n",
    "result4 = re.search(\"\\d+\",result3)\n",
    "search_cnt = int(result4.group())\n",
    "\n",
    "if cnt > search_cnt :\n",
    "    cnt = search_cnt\n",
    "\n",
    "print(\"전체 검색 결과 건수 :\",search_cnt,\"건\")\n",
    "print(\"실제 최종 출력 건수\",cnt)\n",
    "print(\"실체 출력될 최종 페이지수\" , page_cnt)\n",
    "\n",
    "# Step 5. 사용자가 요청한 건수가 많을 경우 리뷰 더보기 버튼을 클릭합니다\n",
    "\n",
    "# 학습목표 1: 댓글 중 일부 내용만 보일 경우 전체 내용을 수집하기\n",
    "# 최초 10건 수집후 댓글 더보기 버튼 클릭\n",
    "# 아래 버튼을 눌러 첫 화면에 총 20건의 댓글이 나오게 만듦\n",
    "driver.find_element_by_xpath('''//*[@id=\"cbox_module\"]/div/div[9]/a/span[1]''').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# 학습목표 2: 삭제된 댓글이나 항목이 있을 경우 예외처리 하기\n",
    "#Step 6. 20건 출력되어 있는 현재 페이지 리뷰와 점수 등 내용 수집\n",
    "writer_id2=[]\n",
    "review2=[]\n",
    "write_date2=[]\n",
    "gogam=[]\n",
    "gogam_0=[]\n",
    "gogam_1=[]\n",
    "\n",
    "if cnt <= 20 :\n",
    "\n",
    "    f = open(ff_name, 'a',encoding='UTF-8')\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    reple_result = soup.find('div', class_='u_cbox_content_wrap').find('ul')\n",
    "    slist = reple_result.find_all('li')\n",
    "\n",
    "    for li in slist:\n",
    "        count += 1\n",
    "        print(\"\\n\")\n",
    "        print(\"%s 번째 댓글 수집 중 ==================\" %count)\n",
    "        \n",
    "        writer_id = li.find('span', class_='u_cbox_nick').get_text()\n",
    "        print(\"1.작성자ID:\", writer_id)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"총 %s 건 중 %s 번째 리뷰 데이터를 수집합니다==============\" %(cnt,count) + \"\\n\")\n",
    "        f.write(\"1.작성자ID:\"+writer_id + \"\\n\")\n",
    "        writer_id2.append(writer_id)\n",
    "                \n",
    "        try :\n",
    "          review = li.find('span', class_='u_cbox_contents').get_text()\n",
    "        except AttributeError :\n",
    "            review='작성자에 의해 삭제된 댓글입니다'\n",
    "            print(\"2.리뷰 :\",review)\n",
    "        else :\n",
    "            print(\"2.리뷰:\",review)\n",
    "        f.write(\"2.리뷰:\" + review + \"\\n\")\n",
    "        review2.append(review)\n",
    " \n",
    "        write_date = li.find('span',class_='u_cbox_date').get_text()\n",
    "        print('3.작성일자:',write_date)\n",
    "        f.write(\"3.작성일자:\" + write_date + \"\\n\")\n",
    "        write_date2.append(write_date)\n",
    "\n",
    "        gogam = li.find('div', class_='u_cbox_recomm_set').find_all('em')\n",
    "        \n",
    "        try :\n",
    "          g_gogam = gogam[0].text\n",
    "          print('4.공감:',g_gogam)\n",
    "        except IndexError :\n",
    "          g_gogam = '0'\n",
    "          print('4.공감 :',g_gogam)\n",
    "        f.write(\"4.공감:\" + g_gogam + \"\\n\")\n",
    "        gogam_0.append(g_gogam)\n",
    "          \n",
    "        gogam = li.find('div', class_='u_cbox_recomm_set').find_all('em')\n",
    "        \n",
    "        try :\n",
    "            b_gogam = gogam[1].text\n",
    "            print('5.비공감:',b_gogam) \n",
    "        except IndexError :\n",
    "          b_gogam = '0'\n",
    "          print('5.비공감 :',b_gogam)\n",
    "        f.write(\"5.비공감:\" + b_gogam + \"\\n\")\n",
    "        gogam_1.append(b_gogam)\n",
    "        \n",
    "        print(\"\\n\")        \n",
    "        time.sleep(0.2)        \n",
    "    \n",
    "        if count == cnt :\n",
    "             break\n",
    "                   \n",
    "    print(\"%s 건  완료========================================================\" %count)\n",
    "    time.sleep(random.randrange(3,8))  # 3-8 초 사이에 랜덤으로 시간 선택\n",
    "                                       \n",
    "else : \n",
    "      \n",
    "    i = 1\n",
    "        \n",
    "    while (i <= page_cnt-1):\n",
    "        driver.find_element_by_xpath('''//*[@id=\"cbox_module\"]/div/div[9]/a''').click() \n",
    "        time.sleep(3)\n",
    "        i += 1\n",
    "                 \n",
    "    #원하는 건수 만큼의 댓글이 출력 된 후 아래 코드로 한꺼번에 크롤링하여 저장함     \n",
    "\n",
    "    f = open(ff_name, 'a',encoding='UTF-8')\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    reple_result = soup.find('div', class_='u_cbox_content_wrap').find('ul')\n",
    "    slist = reple_result.find_all('li')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for li in slist:\n",
    "        count += 1\n",
    "        print(\"\\n\")\n",
    "        print(\"%s 번째 댓글 수집 중 ==================\" %count)\n",
    "        \n",
    "        writer_id = li.find('span', class_='u_cbox_nick').get_text()\n",
    "        print(\"1.작성자ID:\", writer_id)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"총 %s 건 중 %s 번째 리뷰 데이터를 수집합니다==============\" %(cnt,count) + \"\\n\")\n",
    "        f.write(\"1.작성자ID:\"+writer_id + \"\\n\")\n",
    "        writer_id2.append(writer_id)\n",
    "                \n",
    "        try :\n",
    "          review = li.find('span', class_='u_cbox_contents').get_text()\n",
    "        except AttributeError :\n",
    "            review='작성자에 의해 삭제된 댓글입니다'\n",
    "            print(\"2.리뷰 :\",review)\n",
    "        else :\n",
    "            print(\"2.리뷰:\",review)\n",
    "        f.write(\"2.리뷰:\" + review + \"\\n\")\n",
    "        review2.append(review)\n",
    " \n",
    "        write_date = li.find('span',class_='u_cbox_date').get_text()\n",
    "        print('3.작성일자:',write_date)\n",
    "        f.write(\"3.작성일자:\" + write_date + \"\\n\")\n",
    "        write_date2.append(write_date)\n",
    "\n",
    "        gogam = li.find('div', class_='u_cbox_recomm_set').find_all('em')\n",
    "        \n",
    "        try :\n",
    "            g_gogam = gogam[0].text\n",
    "            print('4.공감:',g_gogam)\n",
    "        except IndexError :\n",
    "          g_gogam = '0'\n",
    "          print('4.공감 :',g_gogam)\n",
    "        f.write(\"4.공감:\" + g_gogam + \"\\n\")\n",
    "        gogam_0.append(g_gogam)\n",
    "          \n",
    "        gogam = li.find('div', class_='u_cbox_recomm_set').find_all('em')\n",
    "        \n",
    "        try :\n",
    "            b_gogam = gogam[1].text\n",
    "            print('5.비공감:',b_gogam) \n",
    "        except IndexError :\n",
    "          b_gogam = '0'\n",
    "          print('5.비공감 :',b_gogam)\n",
    "        f.write(\"5.비공감:\" + b_gogam + \"\\n\")\n",
    "        gogam_1.append(b_gogam)\n",
    "\n",
    "        time.sleep(0.2)\n",
    "                    \n",
    "        if count == cnt :\n",
    "             break\n",
    "        \n",
    "    print(\"%s 건  완료========================================================\" %count)\n",
    "\n",
    "    time.sleep(random.randrange(3,8))  # 3-8 초 사이에 랜덤으로 시간 선택\n",
    "       \n",
    "# 학습목표 3. 수집된 데이터를 표 형태로 저장하기\n",
    "#Step 7. xls 형태와 csv 형태로 저장하기\n",
    "\n",
    "news_reple = pd.DataFrame()\n",
    "news_reple['작성자ID']=pd.Series(writer_id2)\n",
    "news_reple['리뷰내용']=pd.Series(review2)\n",
    "news_reple['작성일자']=pd.Series(write_date2)\n",
    "news_reple['공감횟수']=pd.Series(gogam_0)\n",
    "news_reple['비공감횟수']=pd.Series(gogam_1)\n",
    "\n",
    "# csv 형태로 저장하기\n",
    "news_reple.to_csv(fc_name,encoding=\"utf-8-sig\",index=True)\n",
    "\n",
    "# 엑셀 형태로 저장하기\n",
    "news_reple.to_excel(fx_name ,index=True)\n",
    "\n",
    "# Step 8. 요약 정보 출력하기\n",
    "\n",
    "e_time = time.time( )\n",
    "t_time = e_time - s_time\n",
    "\n",
    "print(\"\\n\") \n",
    "print(\"=\" *80)\n",
    "print(\"1.요청된 총 %s 건의 리뷰 중에서 실제 크롤링 된 리뷰수는 %s 건입니다\" %(cnt,count))\n",
    "print(\"2.총 소요시간은 %s 초 입니다 \" %round(t_time,1))\n",
    "print(\"3.파일 저장 완료: txt 파일명 : %s \" %ff_name)\n",
    "print(\"4.파일 저장 완료: csv 파일명 : %s \" %fc_name)\n",
    "print(\"5.파일 저장 완료: xls 파일명 : %s \" %fx_name)\n",
    "print(\"=\" *80)\n",
    "\n",
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
